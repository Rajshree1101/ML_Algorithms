{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3275a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db938a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe().T\n",
    "data.head()\n",
    "data.tail()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f72378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(data['numerical_column'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for all numerical columns\n",
    "sns.pairplot(data)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a398db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2accd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3254bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical =data.select_dtypes(include=['object']).columns\n",
    "numeric=data.select_dtypes(include=np.number).columns\n",
    "numeric=data.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical _null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa793d",
   "metadata": {},
   "source": [
    "#### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for ordinal categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_column :\n",
    "    df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788b45f",
   "metadata": {},
   "source": [
    "###  Replace categorical null valueswith mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Separate categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create SimpleImputer with strategy='most_frequent'\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute categorical columns\n",
    "df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Impute missing values\n",
    "df= pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Inverse transform the encoded values back to original categorical values\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoders[col].inverse_transform(df[col].astype(int))\n",
    "\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff8fff",
   "metadata": {},
   "source": [
    "### Replace numerical null values with mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceabd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "for numerical_column in numerical_columns:\n",
    "    df.loc[:, numerical_column].fillna(df[numerical_column].mean(), inplace=True)\n",
    "\n",
    "(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9851389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b691d",
   "metadata": {},
   "source": [
    "###  Outlier detection and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17986a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(0.25)\n",
    "Q3=df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "outliers=((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.mask(outliers,df.median(),axis=0)\n",
    "# Fill NaN values with median before calculating\n",
    "df.fillna(df.median(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeca037",
   "metadata": {},
   "source": [
    "###   Skewness and box cox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming you have a DataFrame 'df'\n",
    "if data.skew().max() > 0.5:  # Check if any column has skewness > 1\n",
    "    # Apply Box-Cox transformation to each numeric column\n",
    "    numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        data[col] = stats.boxcox(data[col] + 1)[0]  # Add 1 to handle non-positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, skew\n",
    "\n",
    "\n",
    "# Assuming 'data' is your DataFrame and you have already handled NaN and duplicates\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Function to handle skewness and apply Box-Cox transformation\n",
    "def handle_skewness(data, numeric_cols, skew_threshold=0.5):\n",
    "    skewed_cols = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Calculate skewness\n",
    "        col_skewness = skew(data[col])\n",
    "        \n",
    "        # Check if the skewness is significant\n",
    "        if abs(col_skewness) > skew_threshold:\n",
    "            skewed_cols.append(col)\n",
    "            if (data[col] > 0).all():\n",
    "                # Apply Box-Cox transformation\n",
    "                data[col], _ = boxcox(data[col])\n",
    "            else:\n",
    "                # Handle non-positive values by shifting the data\n",
    "                min_value = data[col].min()\n",
    "                data[col] = data[col] - min_value + 1\n",
    "                data[col], _ = boxcox(data[col])\n",
    "    \n",
    "    return data, skewed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74968356",
   "metadata": {},
   "outputs": [],
   "source": [
    " handle_skewness(data, numeric_cols, skew_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a356b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27f0cf",
   "metadata": {},
   "source": [
    "###  Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X=df.drop('SalePrice',axis=1)\n",
    "y=df['SalePrice']\n",
    "\n",
    "best_features=SelectKBest(score_func=f_regression,k=10).fit(X,y)\n",
    "feature_names=list(X.columns)\n",
    "for feature,score in zip(feature_names,best_features.scores_):\n",
    "    print(feature,score)\n",
    "selected_indices=best_features.get_support(indices=True)\n",
    "selected_features=[feature_names[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51717a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1c2de",
   "metadata": {},
   "source": [
    "###  Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b41b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "numerical_column = df.select_dtypes(include=np.number).columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_column ] = scaler.fit_transform(df[numerical_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_columns = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Reshape and scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e691d6b",
   "metadata": {},
   "source": [
    "###  Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e886eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607266cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X=df[['OverallQual',\n",
    " 'YearBuilt',\n",
    " 'TotalBsmtSF',\n",
    " '1stFlrSF',\n",
    " 'GrLivArea',\n",
    " 'FullBath',\n",
    " 'GarageYrBlt',\n",
    " 'GarageFinish',\n",
    " 'GarageCars',\n",
    " 'GarageArea']]\n",
    "y=df['SalePrice']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "rf_regressor=RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rf_regressor.fit(X_train,y_train)\n",
    "y_pred=rf_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "X=data[[]]\n",
    "y=data[[]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da110",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (R2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4952a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e11e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdfe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cd698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c45f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c433a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852d0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076f23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ff16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KNN imputer for more sophisticated imputation (available in the sklearn library).\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[['categorical_column']] = imputer.fit_transform(df[['categorical_column']])\n",
    "\n",
    "## Replace it with the constant value\n",
    "df['categorical_column'] = df['categorical_column'].fillna('Missing')\n",
    "\n",
    "# Replace null values with the most frequent value (mode) of the column.\n",
    "df['category'].fillna(df['category'].mode()[0], inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Replace null values with a constant value, such as 'Unknown' or 'Missing'.\n",
    "df['categorical_column'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numeric null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "df['numeric_column'].fillna(df['numeric_column'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(0.25)\n",
    "Q3=df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "outliers=((df<(Q1-1.5*IQR))| (df>(Q3+1.5*IQR))).sum()\n",
    "outliers\n",
    "# Replace outliers with median\n",
    "df = df.mask(outliers, df.median(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e20ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, skew\n",
    "\n",
    "\n",
    "# Assuming 'data' is your DataFrame and you have already handled NaN and duplicates\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Function to handle skewness and apply Box-Cox transformation\n",
    "def handle_skewness(data, numeric_cols, skew_threshold=0.5):\n",
    "    skewed_cols = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Calculate skewness\n",
    "        col_skewness = skew(data[col])\n",
    "        \n",
    "        # Check if the skewness is significant\n",
    "        if abs(col_skewness) > skew_threshold:\n",
    "            skewed_cols.append(col)\n",
    "            if (data[col] > 0).all():\n",
    "                # Apply Box-Cox transformation\n",
    "                data[col], _ = boxcox(data[col])\n",
    "            else:\n",
    "                # Handle non-positive values by shifting the data\n",
    "                min_value = data[col].min()\n",
    "                data[col] = data[col] - min_value + 1\n",
    "                data[col], _ = boxcox(data[col])\n",
    "    \n",
    "    return data, skewed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Label encoding for ordinal categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# One-hot encoding for nominal categorical variables\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46397ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282450e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X=df.drop('SalePrice',axis=1)\n",
    "y=df['SalePrice']\n",
    "\n",
    "best_features=SelectKBest(score_func=f_regression,k=10).fit(X,y)\n",
    "feature_names=list(X.columns)\n",
    "for feature,score in zip(feature_names,best_features.scores_):\n",
    "    print(feature,score)\n",
    "selected_indices=best_features.get_support(indices=True)\n",
    "selected_features=[feature_names[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1afde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "X=data[[]]\n",
    "y=data[[]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c477d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b8617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23acaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c5071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b393619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1840b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474c185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ea591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709802cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fee585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f82250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ecbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5a361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f52fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30994951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff6f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf84c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
