{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3275a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db639fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe().T\n",
    "data.head()\n",
    "data.tail()\n",
    "data.columns\n",
    "data.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f72378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102687aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.drop_duplicates(subset='App',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 category\n",
    "data[\"Category\"].value_counts(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1e3792",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirline\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      2\u001b[0m a\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating received by users\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "a=data.groupby('Airline').agg({'Price':\"max\"})\n",
    "a.plot.bar()\n",
    "plt.ylabel(\"Rating received by users\")\n",
    "\n",
    "a=data.groupby('Airline').agg({'Duration_min':'min'})\n",
    "a.plot.bar()\n",
    "plt.ylabel(\"Rating received by users\")\n",
    "\n",
    "\n",
    "a=data.groupby('Airline').agg({'Duration_min':'counts'})\n",
    "a.plot.bar()\n",
    "plt.ylabel(\"Rating received by users\")\n",
    "\n",
    "a=data.groupby('Airline').agg({'Duration_min':'sum'}).plot.barh()\n",
    "plt.title()\n",
    "plt.ylabel(\"Rating received by users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff258b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_matrix = data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.histplot(data['numerical_column'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for all numerical columns , Multivariate plot\n",
    "sns.pairplot(data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Bivariate plot\n",
    "# Plot scatter plots\n",
    "pd.plotting.scatter_matrix(df, figsize=(10, 10), diagonal='kde')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# What is the percentage of positive,negative,neutral sentiments?\n",
    "values=user_reviews_data[\"Sentiment\"].value_counts(ascending=False).head(5)\n",
    "labels=['Positive','Negative','Neutral']\n",
    "plt.pie(values,labels=labels, autopct='%1.1f%%', explode=[0.01, 0.01, 0.01])\n",
    "plt.legend(bbox_to_anchor=(0.9, 0, 0.5, 1))\n",
    "plt.title('percentage of positive,negative,neutral sentiments')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adce4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19581705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3254bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical =data.select_dtypes(include=['object']).columns\n",
    "numeric=data.select_dtypes(include=np.number).columns\n",
    "numeric=data.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical _null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f27f6",
   "metadata": {},
   "source": [
    "#### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for ordinal categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_column :\n",
    "    df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c286b",
   "metadata": {},
   "source": [
    "###  Replace categorical null valueswith mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7462e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Separate categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create SimpleImputer with strategy='most_frequent'\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute categorical columns\n",
    "df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd24925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Impute missing values\n",
    "df= pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Inverse transform the encoded values back to original categorical values\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoders[col].inverse_transform(df[col].astype(int))\n",
    "\n",
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98073f05",
   "metadata": {},
   "source": [
    "### Replace numerical null values with mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "for numerical_column in numerical_columns:\n",
    "    df.loc[:, numerical_column].fillna(df[numerical_column].mean(), inplace=True)\n",
    "\n",
    "(df)\n",
    "\n",
    "data[\"Rating\"].fillna(data[\"Rating\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6407d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f144b",
   "metadata": {},
   "source": [
    "###  Outlier detection and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e79e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(0.25)\n",
    "Q3=df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "outliers=((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.mask(outliers,df.median(),axis=0)\n",
    "# Fill NaN values with median before calculating\n",
    "df.fillna(df.median(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14202a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f5236b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobustScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mRobustScaler\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Fit and transform the data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobustScaler' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# Display the original and scaled DataFrames\n",
    "\n",
    "(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nScaled DataFrame:\\n\", scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf2731",
   "metadata": {},
   "source": [
    "###  Unique entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf19ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "for i in numerical_columns:\n",
    "  print(i)\n",
    "  print (data[i].unique())\n",
    "  print(\"/n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f46ec",
   "metadata": {},
   "source": [
    "### Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfa816a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Changing dtype\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Defining columns and their dtypes:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m convert_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviews\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstalls\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m      6\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent Rating\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenres\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent Ver\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m      7\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAndroid Ver\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mstr\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.dtypes\n",
    "\n",
    "# Changing dtype\n",
    "# Defining columns and their dtypes:\n",
    "convert_dict = {'App':str, 'Category':str, 'Rating':float, 'Reviews':str, 'Size':str, 'Installs':str, 'Type':str,\n",
    "       'Price':str, 'Content Rating':str, 'Genres':str, 'Current Ver':str,\n",
    "       'Android Ver':str}\n",
    "\n",
    "\n",
    "data.astype(convert_dict)\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fca84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea7531e5",
   "metadata": {},
   "source": [
    "###   Skewness and box cox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85858bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming you have a DataFrame 'df'\n",
    "if data.skew().max() > 0.5:  # Check if any column has skewness > 1\n",
    "    # Apply Box-Cox transformation to each numeric column\n",
    "    numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        data[col] = stats.boxcox(data[col] + 1)[0]  # Add 1 to handle non-positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d76595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, skew\n",
    "\n",
    "\n",
    "# Assuming 'data' is your DataFrame and you have already handled NaN and duplicates\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Function to handle skewness and apply Box-Cox transformation\n",
    "def handle_skewness(data, numeric_cols, skew_threshold=0.5):\n",
    "    skewed_cols = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Calculate skewness\n",
    "        col_skewness = skew(data[col])\n",
    "        \n",
    "        # Check if the skewness is significant\n",
    "        if abs(col_skewness) > skew_threshold:\n",
    "            skewed_cols.append(col)\n",
    "            if (data[col] > 0).all():\n",
    "                # Apply Box-Cox transformation\n",
    "                data[col], _ = boxcox(data[col])\n",
    "            else:\n",
    "                # Handle non-positive values by shifting the data\n",
    "                min_value = data[col].min()\n",
    "                data[col] = data[col] - min_value + 1\n",
    "                data[col], _ = boxcox(data[col])\n",
    "    \n",
    "    return data, skewed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763f626",
   "metadata": {},
   "outputs": [],
   "source": [
    " handle_skewness(data, numeric_cols, skew_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c40d5",
   "metadata": {},
   "source": [
    "###  Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26296b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "x=data.drop('defects',axis=1)\n",
    "y=data['defects']\n",
    " \n",
    "best_features=SelectKBest(score_func=f_regression,k=11).fit(x,y)\n",
    "\n",
    "selected_features=[feature for feature, score in zip(x.columns,best_features.score_) if score>0]\n",
    "print('Selected Features:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ee09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X=df.drop('SalePrice',axis=1)\n",
    "y=df['SalePrice']\n",
    "\n",
    "best_features=SelectKBest(score_func=f_regression,k=10).fit(X,y)\n",
    "feature_names=list(X.columns)\n",
    "for feature,score in zip(feature_names,best_features.scores_):\n",
    "    print(feature,score)\n",
    "selected_indices=best_features.get_support(indices=True)\n",
    "selected_features=[feature_names[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e059168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "x = train.drop('price_range', axis=1)\n",
    "y = train['price_range']\n",
    "\n",
    "# Select the 11 best features\n",
    "selector = SelectKBest(score_func=f_regression, k=11)\n",
    "selector.fit(x, y)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = x.columns[selector.get_support()].tolist()\n",
    "\n",
    "print('Selected features:', selected_features)\n",
    "\n",
    "# If you want to see the scores\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': x.columns,\n",
    "    'Score': selector.scores_\n",
    "})\n",
    "print('\\nFeature scores:')\n",
    "print(feature_scores.sort_values('Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8756574",
   "metadata": {},
   "source": [
    "###  Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_column = df.select_dtypes(include=np.number).columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_column ] = scaler.fit_transform(df[numerical_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_columns = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Reshape and scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae7a70",
   "metadata": {},
   "source": [
    "###  Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871889fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e885285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X=df[['OverallQual',\n",
    " 'YearBuilt',\n",
    " 'TotalBsmtSF',s\n",
    " '1stFlrSF',\n",
    " 'GrLivArea',\n",
    " 'FullBath',\n",
    " 'GarageYrBlt',\n",
    " 'GarageFinish',\n",
    " 'GarageCars',\n",
    " 'GarageArea']]\n",
    "y=df['SalePrice']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "rf_regressor=RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rf_regressor.fit(X_train,y_train)\n",
    "y_pred=rf_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "X=data[[]]\n",
    "y=data[[]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (R2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e77ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Prepare the training data\n",
    "X_train_full = train.drop('price_range', axis=1)\n",
    "y_train_full = train['price_range']\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = test.drop('id', axis=1)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_regressor.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Results:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# # If you're satisfied with the model, you can retrain on the full training data\n",
    "# rf_regressor_final = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf_regressor_final.fit(X_train_full, y_train_full)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_test_pred = rf_regressor_final.predict(X_test)\n",
    "\n",
    "# # If you want to save the predictions\n",
    "# test['predicted_price_range'] = y_test_pred\n",
    "\n",
    "# print(\"\\nTest predictions have been saved to 'test_predictions.csv'\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_full.columns,\n",
    "    'importance': rf_regressor_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3fe29",
   "metadata": {},
   "source": [
    "### Visualization using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64073a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c71de",
   "metadata": {},
   "source": [
    "### scatterplot():\n",
    "1) Scatter plot for showing the relationship between two numerical variables.\n",
    "\n",
    "sns.scatterplot(x='x', y='y', data=df)\n",
    "\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### lineplot():\n",
    "2) Line plot for continuous data over a time interval.\n",
    "\n",
    "sns.lineplot(x='x', y='y', data=df)\n",
    "\n",
    "plt.title('Line Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Relplot\n",
    "A figure-level function for creating scatter or line plots.\n",
    "\n",
    "sns.relplot(x='x', y='y', kind='scatter', data=df)\n",
    "\n",
    "plt.title('Relational Plot - Scatter')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Pairplot\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "values=play_store_data[\"Category\"].value_counts()\n",
    "\n",
    "labels=play_store_data[\"Category\"].value_counts().index\n",
    "\n",
    "plt.pie(values,labels=labels, autopct='%1.2f%%')\n",
    "\n",
    "plt.title('% of apps share in each Category', fontsize = 25)\n",
    "\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200c5ea",
   "metadata": {},
   "source": [
    "## Categorical Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa343364",
   "metadata": {},
   "source": [
    "### stripplot(): \n",
    "\n",
    "Scatter plot for categorical data.\n",
    "\n",
    "df_cat = pd.DataFrame({'category': ['A', 'B', 'C'], 'value': [10, 20, 15]})\n",
    "\n",
    "sns.stripplot(x='category', y='value', data=df_cat)\n",
    "\n",
    "plt.title('Strip Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### boxplot(): \n",
    "Box plot for showing the distribution of categorical data\n",
    ".\n",
    "sns.boxplot(x='category', y='value', data=df_cat)\n",
    "\n",
    "plt.title('Box Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### barplot(): \n",
    "Bar plot for categorical data.\n",
    "\n",
    "sns.barplot(x='category', y='value', data=df_cat)\n",
    "\n",
    "plt.title('Bar Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### countplot():\n",
    "Bar plot showing the count of observations in each categorical bin.\n",
    "\n",
    "sns.countplot(x='category', data=df_cat)\n",
    "\n",
    "plt.title('Count Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bd6ed",
   "metadata": {},
   "source": [
    "## Distribution Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5f788",
   "metadata": {},
   "source": [
    "### histplot(): Histogram for showing the distribution of a single variable.\n",
    "    \n",
    "sns.histplot(df['y'])\n",
    "\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "numerical=list(train.select_dtypes(include=np.number).columns)\n",
    "numerical\n",
    "\n",
    "for i in numerical:\n",
    "\n",
    "    sns.histplot(train[i])\n",
    "    \n",
    "    plt.title('Histogram')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "### kdeplot(): Kernel Density Estimation plot for showing the distribution of a variable.\n",
    "    \n",
    "sns.kdeplot(df['y'])\n",
    "\n",
    "plt.title('KDE Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### rugplot(): Adds small vertical lines at each data point in a distribution.\n",
    "\n",
    "sns.rugplot(df['y'])\n",
    "\n",
    "plt.title('Rug Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### ecdfplot(): Empirical Cumulative Distribution Function plot.\n",
    "    \n",
    "sns.ecdfplot(df['y'])\n",
    "\n",
    "plt.title('ECDF Plot')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37056c8",
   "metadata": {},
   "source": [
    "## Matrix Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b665b1",
   "metadata": {},
   "source": [
    "### heatmap(): Heatmap for showing data in matrix form with color encoding.\n",
    "\n",
    "df_matrix = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6], 'z': [7, 8, 9]})\n",
    "\n",
    "sns.heatmap(df_matrix)\n",
    "\n",
    "plt.title('Heatmap')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### clustermap(): Hierarchical clustering of data represented as a heatmap.\n",
    "\n",
    "sns.clustermap(df_matrix)\n",
    "\n",
    "plt.title('Clustermap')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b965e8b",
   "metadata": {},
   "source": [
    "###  Regression Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf62741",
   "metadata": {},
   "source": [
    "### regplot(): Scatter plot with a regression line.\n",
    "\n",
    "sns.regplot(x='x', y='y', data=df)\n",
    "\n",
    "plt.title('Regression Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### lmplot(): A figure-level function for creating linear model plots.\n",
    "\n",
    "sns.lmplot(x='x', y='y', data=df)\n",
    "\n",
    "plt.title('Linear Model Plot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### residplot(): Residual plot for assessing the fit of a regression.\n",
    "    \n",
    "sns.residplot(x='x', y='y', data=df)\n",
    "\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333afd9",
   "metadata": {},
   "source": [
    "## Multi-plot Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08458ee1",
   "metadata": {},
   "source": [
    "### FacetGrid: A class for drawing multiple plots in a grid.\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "g = sns.FacetGrid(tips, col='time')\n",
    "\n",
    "g.map(sns.scatterplot, 'total_bill', 'tip')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### PairGrid: A class for drawing multiple bivariate plots in a grid.\n",
    "\n",
    "g = sns.PairGrid(tips)\n",
    "\n",
    "g.map(sns.scatterplot)\n",
    "plt.show()\n",
    "\n",
    "### pairplot(): Creates a grid of scatter plots for all pairs of numerical variables in a dataset.\n",
    "\n",
    "sns.pairplot(tips)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### JointGrid: A class for drawing plots with multiple axes.\n",
    "\n",
    "g = sns.JointGrid(data=tips, x='total_bill', y='tip')\n",
    "\n",
    "g.plot(sns.scatterplot, sns.histplot)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a0df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f12ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ad3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39fc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d34f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cbe01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KNN imputer for more sophisticated imputation (available in the sklearn library).\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[['categorical_column']] = imputer.fit_transform(df[['categorical_column']])\n",
    "\n",
    "## Replace it with the constant value\n",
    "df['categorical_column'] = df['categorical_column'].fillna('Missing')\n",
    "\n",
    "# Replace null values with the most frequent value (mode) of the column.\n",
    "df['category'].fillna(df['category'].mode()[0], inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Replace null values with a constant value, such as 'Unknown' or 'Missing'.\n",
    "df['categorical_column'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numeric null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "df['numeric_column'].fillna(df['numeric_column'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(0.25)\n",
    "Q3=df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "outliers=((df<(Q1-1.5*IQR))| (df>(Q3+1.5*IQR))).sum()\n",
    "outliers\n",
    "# Replace outliers with median\n",
    "df = df.mask(outliers, df.median(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e20ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, skew\n",
    "\n",
    "\n",
    "# Assuming 'data' is your DataFrame and you have already handled NaN and duplicates\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Function to handle skewness and apply Box-Cox transformation\n",
    "def handle_skewness(data, numeric_cols, skew_threshold=0.5):\n",
    "    skewed_cols = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Calculate skewness\n",
    "        col_skewness = skew(data[col])\n",
    "        \n",
    "        # Check if the skewness is significant\n",
    "        if abs(col_skewness) > skew_threshold:\n",
    "            skewed_cols.append(col)\n",
    "            if (data[col] > 0).all():\n",
    "                # Apply Box-Cox transformation\n",
    "                data[col], _ = boxcox(data[col])\n",
    "            else:\n",
    "                # Handle non-positive values by shifting the data\n",
    "                min_value = data[col].min()\n",
    "                data[col] = data[col] - min_value + 1\n",
    "                data[col], _ = boxcox(data[col])\n",
    "    \n",
    "    return data, skewed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Label encoding for ordinal categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# One-hot encoding for nominal categorical variables\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46397ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282450e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X=df.drop('SalePrice',axis=1)\n",
    "y=df['SalePrice']\n",
    "\n",
    "best_features=SelectKBest(score_func=f_regression,k=10).fit(X,y)\n",
    "feature_names=list(X.columns)\n",
    "for feature,score in zip(feature_names,best_features.scores_):\n",
    "    print(feature,score)\n",
    "selected_indices=best_features.get_support(indices=True)\n",
    "selected_features=[feature_names[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1afde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "X=data[[]]\n",
    "y=data[[]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c477d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b8617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23acaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c5071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b393619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1840b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474c185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ea591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709802cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fee585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f82250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ecbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5a361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f52fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30994951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff6f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf84c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
